{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f826824-d452-46dc-8eb1-bfcad82c8085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic==1.10.8 in /usr/local/lib/python3.9/dist-packages (1.10.8)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic==1.10.8) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U pydantic==1.10.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582a2f5b-7fe8-4442-ab63-871f0a5ea2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (0.0.278)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.0.31)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.8.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.23.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (18.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<3,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0056c248-8259-403b-bcc2-e9bfb29a2bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.10)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.20->openai) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.20->openai) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (18.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86efbf58-1864-4797-abef-fed1e74c00bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cohere in /usr/local/lib/python3.9/dist-packages (4.21)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from cohere) (3.8.3)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from cohere) (2.2.1)\n",
      "Requirement already satisfied: fastavro==1.8.2 in /usr/local/lib/python3.9/dist-packages (from cohere) (1.8.2)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.9/dist-packages (from cohere) (6.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.9/dist-packages (from cohere) (1.26.14)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.9/dist-packages (from cohere) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0,>=3.0->cohere) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0,>=3.0->cohere) (18.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2019.11.28)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88ce9f20-a15a-46e9-b744-908ced68bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "concept = '''\n",
    "Gradient Descent is an iterative optimization process that searches for an objective function’s\n",
    " optimum value (Minimum/Maximum). It is one of the most used methods for changing a model’s parameters in\n",
    " order to reduce a cost function in machine learning projects.  \n",
    "The primary goal of gradient descent is to identify the model parameters that provide the maximum accuracy\n",
    " on both training and test datasets. In gradient descent, the gradient is a vector pointing in the general\n",
    " direction of the function’s steepest rise at a particular point. The algorithm might gradually drop towards\n",
    " lower values of the function by moving in the opposite direction of the gradient, until reaching the minimum\n",
    " of the function.\n",
    " '''\n",
    "student_own_words='''\n",
    "Gradient descent is an optimization algorithm that is commonly used to minimize cost functions in\n",
    " machine learning models. It works by iteratively adjusting the model parameters, like the weights and biases\n",
    " in a neural network, in the direction that reduces the cost function.\n",
    "\n",
    "The goal is to converge on the optimal set of parameters that minimize the cost, like the error between\n",
    " predictions and true labels. Gradient descent starts with random initial parameters, then calculates the gradient\n",
    " of the cost function. The gradient tells you which direction to update the parameters to reduce the cost.\n",
    "The parameters are updated by a small amount in the negative gradient direction. This process is repeated until\n",
    "the algorithm converges on a minimum cost.\n",
    "\n",
    "So in summary, gradient descent iteratively fine-tunes the model parameters by calculating the gradient and moving\n",
    " in the direction that reduces the cost function. By repeating this process, it can find the optimal parameters that\n",
    " minimize the cost and maximize model accuracy.\n",
    " '''\n",
    "template =  '''\n",
    "    Read the following concept and a student's in-your-own-words description and evaluate the student's\n",
    "description by the following criteria: \n",
    "- coverage of the core aspects of the concept\n",
    "- clarity and simplicity of the explanation\n",
    "- Identify gaps in understanding and areas that need improvement\n",
    "\n",
    "Provide a score on how well the concept was explained.\n",
    "\n",
    "Concept: `{concept}`\n",
    "\n",
    "Student: `{student_own_words}`\n",
    "Evaluation:\n",
    "'''\n",
    "prompt_template= PromptTemplate(template=template, input_variables=[\"concept\", \"student_own_words\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc2148a3-5c50-47bf-a26c-8f8e78e825f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "colourful_student_own_words= '''Imagine you're standing in a valley and you want to find the lowest point. You can't see the entire valley,\n",
    "but you can look around your immediate area. You notice the ground slopes down more steeply to your left.\n",
    "So you take a step to the left, going downhill. Now you look around again - the slope is still steeper to\n",
    "your left, so you step that way again. You keep doing this, taking steps in the direction of the steepest\n",
    "downward slope, until you can't go any lower - you've reached the valley floor. \n",
    "\n",
    "This is similar to how gradient descent works. We have a function we want to minimize, like the cost of a\n",
    "machine learning model. We can't see the whole function landscape, but we can calculate the slope or gradient\n",
    " at our current position. The gradient tells us which direction to move to go downhill - to lower the cost\n",
    "function. We iteratively take small steps in the negative gradient direction, recalculating the gradient as\n",
    "we go, until we reach the minimum cost. \n",
    "\n",
    "So gradient descent starts at some random point, measures the local gradient, takes a step downhill, and\n",
    "repeats this to \"walk down\" the cost function valley until it reaches the bottom or minimum value. The gradient\n",
    "helps guide each step towards the optimal low point just like walking downhill guides you to the valley floor.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3fbedc5-5762-4c1b-a719-283bf8f7dae5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgetpass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getpass\n\u001b[0;32m----> 2\u001b[0m OPENAI_API_KEY\u001b[38;5;241m=\u001b[39m\u001b[43mgetpass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py:1159\u001b[0m, in \u001b[0;36mKernel.getpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `stream` parameter of `getpass.getpass` will have no effect when using ipykernel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1158\u001b[0m     )\n\u001b[0;32m-> 1159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py:1219\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "OPENAI_API_KEY=getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4877d424-f182-4eac-85f6-7eef02d53abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685692c2-3224-4652-939e-8c637d5c97a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "COHERE_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "372c4d8d-a7fa-41d9-a9f7-c70be5ad4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780de9e-4b3f-455d-905b-7a8ae4fd1f00",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d2321ec-df2d-48ac-bfc4-234e3b65f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3467a3e2-484f-4a2e-9f69-306c6d35b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "openai_llm_chain = LLMChain(llm=openai_llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e99577a-82e4-424f-9a8e-332937d935e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_llm_chain.predict(concept=concept, student_own_words=student_own_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b57e3c0-3ff9-4005-8c76-40b4d3411429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's description of the Gradient Descent concept is quite good. The explanation covers the core aspects of the concept, such as its role in minimizing cost functions in machine learning models, how it iteratively adjusts model parameters, and the process of calculating the gradient and updating parameters in the direction that reduces cost. The explanation is clear, simple, and easy to understand. The goal of the algorithm to find the optimal parameters and maximize model accuracy is also well explained.\n",
      "\n",
      "One potential area for improvement is the explanation of the gradient itself. The student did not fully explain that the gradient is a vector pointing in the direction of the function's steepest rise. Instead, the student simply stated that the gradient tells you which direction to update the parameters. While this is true, it does not fully capture the concept of a gradient. \n",
      "\n",
      "Also, the student didn't mention that the process continues until reaching the minimum of the function. This is an important aspect as it's the stopping criteria for the procedure.\n",
      "\n",
      "Overall, considering the clarity and completeness of the explanation, I would give it a score of 8.5 out of 10.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3ed0aab-11af-46a0-ac64-52e14e9fe4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's explanation is not relevant to the concept of Gradient Descent at all. There seems to be a misunderstanding or a mistake as the student has simply written \"climate change\", which is not related to the concept of Gradient Descent in machine learning. \n",
      "\n",
      "Score: 0/10\n"
     ]
    }
   ],
   "source": [
    "zero_response = openai_llm_chain.predict(concept=concept, student_own_words=\"climate change\")\n",
    "print(zero_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a139a2-c932-428c-8fda-61e5a1b4cddb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0db974e8-fb6d-48b8-a828-181877a6402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb37393e-4851-40c7-a1ca-b9adff6aa644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "openai_llm_chain = LLMChain(llm=openai_llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8bc01e33-e5e0-462d-afe9-799c715e53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_llm_chain.predict(concept=concept, student_own_words=student_own_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02dcdaa6-51cf-4edf-931c-4b2ccd8bd793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's description covers the core aspects of the concept. They mention that gradient descent is an optimization algorithm used to minimize cost functions in machine learning models. They explain that it works by iteratively adjusting the model parameters in the direction that reduces the cost function. They also mention the goal of converging on the optimal set of parameters that minimize the cost.\n",
      "\n",
      "The explanation is clear and simple. The student uses understandable language and provides a step-by-step description of how gradient descent works. They mention the use of random initial parameters, the calculation of the gradient, and the updating of parameters in the negative gradient direction.\n",
      "\n",
      "There are no major gaps in understanding or areas that need improvement. The student accurately describes the iterative nature of gradient descent and its goal of minimizing the cost function.\n",
      "\n",
      "Overall, the student's explanation is well-done and covers the important aspects of the concept. I would give it a score of 4 out of 5.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "081b6621-e3bf-4339-8d99-e797475db4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's response does not address the concept of gradient descent at all. It is unrelated to the concept and does not demonstrate understanding or knowledge of the topic. Therefore, the student's response does not cover any core aspects of the concept, lacks clarity and simplicity, and there are significant gaps in understanding. The score for the explanation would be very low, possibly 1 out of 10.\n"
     ]
    }
   ],
   "source": [
    "zero_response = openai_llm_chain.predict(concept=concept, student_own_words=\"climate change\")\n",
    "print(zero_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb0e0b-1e12-4b73-b6af-0d046c3a2f6d",
   "metadata": {},
   "source": [
    "# Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be5fb681-400c-4916-bd4b-7ab2cf77d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Cohere\n",
    "cohere_llm = Cohere(model=\"command-nightly\", cohere_api_key=COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "92207a64-f29c-4934-9f23-f9d83f90a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "cohere_llm_chain = LLMChain(llm=cohere_llm,prompt=prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "757f3b43-f8be-4c1d-9fe6-8865b61981b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Coverage of the core aspects of the concept: \n",
      "The student's description covers the key aspects of gradient descent, including the iterative optimization process, the objective of finding the minimum/maximum value of an objective function, and the role of gradients in determining the direction of optimization.\n",
      "- Clarity and simplicity of the explanation: \n",
      "The student's description is clear and concise, using simple language to explain the concept. The use of bullet points and a summary helps to break down the concept into manageable parts.\n",
      "- Identify gaps in understanding and areas that need improvement: \n",
      "The student's description does not mention the role of random initial parameters in gradient descent. Additionally, the description could be improved by explaining the process of convergence on a minimum cost, and how gradient descent is used to maximize model accuracy.\n",
      "- Score: \n",
      "The student's description is well-written and covers the core aspects of the concept. However, there are some gaps in understanding that could be improved. Overall, the student's explanation is clear and provides a good understanding of gradient descent.\n",
      "\n",
      "Grading:\n",
      "\n",
      "8/10\n"
     ]
    }
   ],
   "source": [
    "response = cohere_llm_chain.predict(concept=concept, student_own_words=student_own_words)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f92a54a-1006-4291-a699-ba87d13c3c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + The student's explanation is clear and simple, and they provide an analogy that helps to understand the concept.\n",
      "\n",
      "+ The student's explanation covers the core aspects of the concept, including the goal of gradient descent, how it works, and the role of the gradient.\n",
      "\n",
      "- The student's explanation does not mention the importance of finding the optimum value of the objective function or the fact that gradient descent is one of the most used methods for changing a model's parameters in machine learning projects.\n",
      "\n",
      "- The student's explanation does not mention the potential for gradient descent to converge to a local minimum rather than the global minimum.\n",
      "\n",
      "Overall, the student's explanation is clear and provides a good understanding of the concept, but it does not cover all aspects of the concept and there are some areas that could be improved.\n",
      "\n",
      "Score: 8/10\n"
     ]
    }
   ],
   "source": [
    "print(cohere_llm_chain.predict(concept=concept, student_own_words=colourful_student_own_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5eb1e876-e2f8-47f6-95a5-cfb071b9cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The student's explanation of gradient descent is mostly correct, but there are a few areas where it could be improved. First, the student does not fully explain what gradient descent is or how it is used in machine learning. Second, the student does not explain what the \"objective function\" is or how it relates to gradient descent. Third, the student does not explain what the \"cost function\" is or how it relates to gradient descent. Finally, the student does not explain what the \"model parameters\" are or how they relate to gradient descent.\n",
      "\n",
      "Overall, the student's explanation of gradient descent is mostly correct, but it could be improved by explaining the core concepts in more detail.\n"
     ]
    }
   ],
   "source": [
    "zero_response = cohere_llm_chain.predict(concept=concept, student_own_words=\"climate change\")\n",
    "print(zero_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90427ed-48df-4b38-87de-a96f7895f348",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LaMini-Flan-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0866e7a-7420-4e3a-b752-cb4e7ff332b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe9a871f72241889bee86e762f69c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/2.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20d50697d28476ba060f15a9951cc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfae42711d32400889de721c93327ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec22b4e6c22469aa79c69a9cf7f5c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/2.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3c3931d1654547a1dda584473ffb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/860 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef34f32f8fbf44d4a110495f96470619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device has 1 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "model_id = \"MBZUAI/LaMini-Flan-T5-783M\" \n",
    "flan_llm = HuggingFacePipeline.from_model_id(model_id=model_id, task=\"text2text-generation\", model_kwargs={\"temperature\":0, \"max_length\":4096})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80ac4c50-ceb2-4f87-a4ff-4a0d73b56d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "flan_llm_chain = LLMChain(llm=flan_llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96b863bd-64c4-4080-889f-e8ff584b07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = flan_llm_chain.predict(concept=concept, student_own_words=student_own_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf89a849-80b6-4605-8c84-47f006aba594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's description is clear and concise.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5bf9f7c-74f4-41d8-b97e-f57467b41aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's description of the concept of gradient descent is clear and concise. However, there are some areas that need improvement.\n"
     ]
    }
   ],
   "source": [
    "zero_response = flan_llm_chain.predict(concept=concept, student_own_words=\"climate change\")\n",
    "print(zero_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a61034-789d-4148-9889-00cabdd6ef9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LaMini-Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "346b96ef-b2fa-40ab-88a5-726c7e609b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16296fa1fc34c289c0811042ccb411c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/788 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7981d8f55e274c3fab0f0d3ff05b0d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b752a811ef4b9aa01983f73d975d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e155ab53d68348638cd7ad9609db9acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.01M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a88c6dc3814c33aa0bdb8dc6a3f551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906fc1d01a624518baefab51f05a5d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eec5e2debb54bd5b43fd9d85e93d966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920189be17c84f3fa8f34c4655726855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device has 1 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "model_id = \"MBZUAI/LaMini-Neo-1.3B\" \n",
    "neo_llm = HuggingFacePipeline.from_model_id(model_id=model_id, task=\"text-generation\", model_kwargs={\"temperature\":0.5, \"max_length\":4096})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "598a0026-bac7-4cbc-92ab-0ff7028e578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_llm_chain = LLMChain(llm=neo_llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "757b570f-60f1-46ed-8f0a-4ebb8165d74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Input length of input_ids is 451, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = neo_llm_chain.predict(concept=concept, student_own_words=student_own_words)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f43c7cb6-d8af-46de-ac5e-b16e2caf4afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 254, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "zero_response = neo_llm_chain.predict(concept=concept, student_own_words=\"climate change\")\n",
    "print(zero_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1cc746-c515-4114-904b-01e098d519ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
